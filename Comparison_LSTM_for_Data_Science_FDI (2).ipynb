{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "FqEXKXL0kw7Y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**KELOMPOK 10<br>**\n",
        "Dwi Ahmad Dzulhijjah<br>\n",
        "Muhammad NurKholis Majid<br>\n",
        "Almi Yulistia Alwanda<br>\n",
        "Fariz Zakaria<br>\n",
        "Dimas Candra Kusuma<br><br>\n",
        "\n",
        "\n",
        "\n",
        "**FIRE DANGER RATING SISTEM**<br>\n",
        "Importing libraries\n"
      ],
      "metadata": {
        "id": "-6mcRBX3Q872"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AKUISISI DATA"
      ],
      "metadata": {
        "id": "vragGm_pF0pF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2LRWY5yP73o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING AND REVIEWING DATA"
      ],
      "metadata": {
        "id": "YI6xOGfdRcQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OHDIN3GrH7Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84229dbb-7e59-451b-e5bc-ac23b53be07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/MTI/Data Science/Paper/FDRS-KBJ-1-6.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJAXQKPyRf6Y",
        "outputId": "27c2ebad-6e14-42e7-a9bd-6df588837c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7779, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "RAUK2YxlU-LY",
        "outputId": "25911e69-3449-4902-a21d-f7047ae27a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Date  Temp Out  Humidity Out  Wind Speed  sum RainFall  \\\n",
              "0    1/25/2023 0:30      23.4            96         6.4          10.8   \n",
              "1    1/25/2023 1:00      23.2            97         4.8          20.8   \n",
              "2    1/25/2023 1:30      23.2            98         1.6           1.4   \n",
              "3   1/25/2023 10:00      26.1            88         3.2           0.0   \n",
              "4   1/25/2023 10:30      26.1            90         3.2           0.0   \n",
              "..              ...       ...           ...         ...           ...   \n",
              "95   1/26/2023 9:30      23.6            96         1.6           0.2   \n",
              "96   1/27/2023 0:00      23.5            96         1.6           0.0   \n",
              "97   1/27/2023 0:30      23.4            97         0.0           0.0   \n",
              "98   1/27/2023 1:00      23.2            97         0.0           0.0   \n",
              "99   1/27/2023 1:30      22.9            97         0.0           0.0   \n",
              "\n",
              "   RainDescription  Soil Moisture  Soil Temp  FDRS Index FDRS Status  \n",
              "0           Ringan              3       27.8    0.307216      Sedang  \n",
              "1           Sedang              3       27.2    0.285714      Rendah  \n",
              "2    Sangat Ringan              3       27.2    0.250505      Rendah  \n",
              "3      Tidak Hujan              3       26.7    0.329213      Tinggi  \n",
              "4      Tidak Hujan              3       26.7    0.321978      Tinggi  \n",
              "..             ...            ...        ...         ...         ...  \n",
              "95   Sangat Ringan              3       25.6    0.259794      Rendah  \n",
              "96     Tidak Hujan              4       26.1    0.258763      Rendah  \n",
              "97     Tidak Hujan              4       26.1    0.238776      Rendah  \n",
              "98     Tidak Hujan              4       26.1    0.236735      Rendah  \n",
              "99     Tidak Hujan              4       26.1    0.233673      Rendah  \n",
              "\n",
              "[100 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4f4c1f06-b646-4066-bac1-2ad1b5f6969b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Temp Out</th>\n",
              "      <th>Humidity Out</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>sum RainFall</th>\n",
              "      <th>RainDescription</th>\n",
              "      <th>Soil Moisture</th>\n",
              "      <th>Soil Temp</th>\n",
              "      <th>FDRS Index</th>\n",
              "      <th>FDRS Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/25/2023 0:30</td>\n",
              "      <td>23.4</td>\n",
              "      <td>96</td>\n",
              "      <td>6.4</td>\n",
              "      <td>10.8</td>\n",
              "      <td>Ringan</td>\n",
              "      <td>3</td>\n",
              "      <td>27.8</td>\n",
              "      <td>0.307216</td>\n",
              "      <td>Sedang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/25/2023 1:00</td>\n",
              "      <td>23.2</td>\n",
              "      <td>97</td>\n",
              "      <td>4.8</td>\n",
              "      <td>20.8</td>\n",
              "      <td>Sedang</td>\n",
              "      <td>3</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/25/2023 1:30</td>\n",
              "      <td>23.2</td>\n",
              "      <td>98</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Sangat Ringan</td>\n",
              "      <td>3</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.250505</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/25/2023 10:00</td>\n",
              "      <td>26.1</td>\n",
              "      <td>88</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>3</td>\n",
              "      <td>26.7</td>\n",
              "      <td>0.329213</td>\n",
              "      <td>Tinggi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/25/2023 10:30</td>\n",
              "      <td>26.1</td>\n",
              "      <td>90</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>3</td>\n",
              "      <td>26.7</td>\n",
              "      <td>0.321978</td>\n",
              "      <td>Tinggi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1/26/2023 9:30</td>\n",
              "      <td>23.6</td>\n",
              "      <td>96</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sangat Ringan</td>\n",
              "      <td>3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.259794</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1/27/2023 0:00</td>\n",
              "      <td>23.5</td>\n",
              "      <td>96</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>4</td>\n",
              "      <td>26.1</td>\n",
              "      <td>0.258763</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1/27/2023 0:30</td>\n",
              "      <td>23.4</td>\n",
              "      <td>97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>4</td>\n",
              "      <td>26.1</td>\n",
              "      <td>0.238776</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1/27/2023 1:00</td>\n",
              "      <td>23.2</td>\n",
              "      <td>97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>4</td>\n",
              "      <td>26.1</td>\n",
              "      <td>0.236735</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1/27/2023 1:30</td>\n",
              "      <td>22.9</td>\n",
              "      <td>97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>4</td>\n",
              "      <td>26.1</td>\n",
              "      <td>0.233673</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f4c1f06-b646-4066-bac1-2ad1b5f6969b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-eea979c4-0045-43e3-af9a-689af40e6d2a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eea979c4-0045-43e3-af9a-689af40e6d2a')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-eea979c4-0045-43e3-af9a-689af40e6d2a button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f4c1f06-b646-4066-bac1-2ad1b5f6969b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f4c1f06-b646-4066-bac1-2ad1b5f6969b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "GzwSGrwobWq8",
        "outputId": "5aeebe94-0614-411f-de70-e7bf017c902e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Date  Temp Out  Humidity Out  Wind Speed  sum RainFall  \\\n",
              "7679  6/6/2023 10:00      31.2            84         0.0           0.0   \n",
              "7680  6/6/2023 10:30      29.4            89         1.6           0.0   \n",
              "7681  6/6/2023 11:00      28.5            91         0.0           0.0   \n",
              "7682  6/6/2023 11:30      27.8            94         0.0           0.0   \n",
              "7683  6/6/2023 12:00      27.4            94         0.0           0.0   \n",
              "...              ...       ...           ...         ...           ...   \n",
              "7774   6/8/2023 0:30      25.9            95         0.0           0.0   \n",
              "7775   6/8/2023 1:00      27.4            91         1.6           0.0   \n",
              "7776   6/8/2023 1:30      28.4            86         1.6           0.0   \n",
              "7777   6/8/2023 2:00      29.6            82         1.6           0.0   \n",
              "7778   6/8/2023 2:30      29.7            81         3.2           0.0   \n",
              "\n",
              "     RainDescription  Soil Moisture  Soil Temp  FDRS Index FDRS Status  \n",
              "7679     Tidak Hujan              7       31.7    0.367059     Extreme  \n",
              "7680     Tidak Hujan              7       31.7    0.344444     Extreme  \n",
              "7681     Tidak Hujan              7       31.7    0.309783      Sedang  \n",
              "7682     Tidak Hujan              7       31.1    0.292632      Rendah  \n",
              "7683     Tidak Hujan              7       31.1    0.288421      Rendah  \n",
              "...              ...            ...        ...         ...         ...  \n",
              "7774     Tidak Hujan              9       27.2    0.269792      Rendah  \n",
              "7775     Tidak Hujan              9       27.2    0.315217      Sedang  \n",
              "7776     Tidak Hujan              9       27.2    0.344828     Extreme  \n",
              "7777     Tidak Hujan              9       27.8    0.375904     Extreme  \n",
              "7778     Tidak Hujan              9       28.3    0.401220     Extreme  \n",
              "\n",
              "[100 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-38233bf5-f7d4-49cf-a1ba-3f04e1b555a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Temp Out</th>\n",
              "      <th>Humidity Out</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>sum RainFall</th>\n",
              "      <th>RainDescription</th>\n",
              "      <th>Soil Moisture</th>\n",
              "      <th>Soil Temp</th>\n",
              "      <th>FDRS Index</th>\n",
              "      <th>FDRS Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7679</th>\n",
              "      <td>6/6/2023 10:00</td>\n",
              "      <td>31.2</td>\n",
              "      <td>84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>7</td>\n",
              "      <td>31.7</td>\n",
              "      <td>0.367059</td>\n",
              "      <td>Extreme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7680</th>\n",
              "      <td>6/6/2023 10:30</td>\n",
              "      <td>29.4</td>\n",
              "      <td>89</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>7</td>\n",
              "      <td>31.7</td>\n",
              "      <td>0.344444</td>\n",
              "      <td>Extreme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7681</th>\n",
              "      <td>6/6/2023 11:00</td>\n",
              "      <td>28.5</td>\n",
              "      <td>91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>7</td>\n",
              "      <td>31.7</td>\n",
              "      <td>0.309783</td>\n",
              "      <td>Sedang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7682</th>\n",
              "      <td>6/6/2023 11:30</td>\n",
              "      <td>27.8</td>\n",
              "      <td>94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>7</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.292632</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7683</th>\n",
              "      <td>6/6/2023 12:00</td>\n",
              "      <td>27.4</td>\n",
              "      <td>94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>7</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.288421</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7774</th>\n",
              "      <td>6/8/2023 0:30</td>\n",
              "      <td>25.9</td>\n",
              "      <td>95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>9</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.269792</td>\n",
              "      <td>Rendah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7775</th>\n",
              "      <td>6/8/2023 1:00</td>\n",
              "      <td>27.4</td>\n",
              "      <td>91</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>9</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.315217</td>\n",
              "      <td>Sedang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7776</th>\n",
              "      <td>6/8/2023 1:30</td>\n",
              "      <td>28.4</td>\n",
              "      <td>86</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>9</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>Extreme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7777</th>\n",
              "      <td>6/8/2023 2:00</td>\n",
              "      <td>29.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>0.375904</td>\n",
              "      <td>Extreme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7778</th>\n",
              "      <td>6/8/2023 2:30</td>\n",
              "      <td>29.7</td>\n",
              "      <td>81</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Tidak Hujan</td>\n",
              "      <td>9</td>\n",
              "      <td>28.3</td>\n",
              "      <td>0.401220</td>\n",
              "      <td>Extreme</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38233bf5-f7d4-49cf-a1ba-3f04e1b555a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2b38d82a-0907-4789-a650-ff3ac39163a3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b38d82a-0907-4789-a650-ff3ac39163a3')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2b38d82a-0907-4789-a650-ff3ac39163a3 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38233bf5-f7d4-49cf-a1ba-3f04e1b555a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38233bf5-f7d4-49cf-a1ba-3f04e1b555a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "gh54ATRu70Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "0wpCra3_QFyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "dataset = df.copy()\n",
        "\n",
        "# Mengubah kolom Date menjadi tipe data datetime\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
        "\n",
        "# Mengurutkan dataset berdasarkan kolom Date\n",
        "dataset = dataset.sort_values('Date')\n",
        "\n",
        "# Memilih fitur yang akan digunakan untuk prediksi\n",
        "features = ['Temp Out', 'Humidity Out', 'Wind Speed', 'sum RainFall', 'Soil Moisture', 'FDRS Index']\n",
        "\n",
        "# Mengambil data yang akan digunakan\n",
        "data = dataset[features].values\n",
        "\n",
        "# Normalisasi data ke rentang 0-1\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Menentukan jumlah timestep dan fitur\n",
        "timesteps = 10  # Jumlah data sebelumnya yang akan digunakan untuk prediksi\n",
        "n_features = len(features)\n",
        "\n",
        "# Membuat dataset terpisah untuk pelatihan dan pengujian\n",
        "train_size = int(len(data_scaled) * 0.8)  # 80% data untuk pelatihan\n",
        "train_data = data_scaled[:train_size]\n",
        "test_data = data_scaled[train_size:]\n",
        "\n",
        "# Membagi data menjadi input dan output\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X.append(data[i:i + timesteps])\n",
        "        y.append(data[i + timesteps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "train_X, train_y = create_sequences(train_data, timesteps)\n",
        "test_X, test_y = create_sequences(test_data, timesteps)\n",
        "\n",
        "# Membangun model LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(timesteps, n_features)))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Melatih model\n",
        "history_LSTM = model.fit(train_X, train_y,validation_data=(test_X, test_y), epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Memprediksi data pengujian\n",
        "predicted = model.predict(test_X)\n",
        "\n",
        "# Mengembalikan data ke skala aslinya\n",
        "predicted = scaler.inverse_transform(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6yni5lk714J",
        "outputId": "48ef7ecb-b106-4393-8a6b-31a1f5bf8735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - 5s 12ms/step - loss: 0.0174 - val_loss: 0.0036\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0042 - val_loss: 0.0029\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0032 - val_loss: 0.0021\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0030 - val_loss: 0.0020\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0029 - val_loss: 0.0019\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0027 - val_loss: 0.0018\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "49/49 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SIMPAN PERFORMA"
      ],
      "metadata": {
        "id": "P2oWLSuwF_7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math"
      ],
      "metadata": {
        "id": "wQdGb5GsJVcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe to store the evaluation results\n",
        "results = pd.DataFrame(columns=['Algorithm',\n",
        "                                'MAE',\n",
        "                                'MSE',\n",
        "                                'RMSE',\n",
        "                                'CV Predicted',\n",
        "                                'CV Actual'])"
      ],
      "metadata": {
        "id": "cTTVqLH9JZd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the actual test data and predicted values for LSTM\n",
        "lstm_actual = test_data[timesteps:]\n",
        "lstm_predicted = predicted\n",
        "\n",
        "lstm_std_act = np.std(lstm_actual)\n",
        "lstm_std_pred = np.std(lstm_predicted)\n",
        "\n",
        "# Calculate evaluation metrics for LSTM\n",
        "lstm_mae = mean_absolute_error(lstm_actual, lstm_predicted)\n",
        "lstm_mse = mean_squared_error(lstm_actual, lstm_predicted)\n",
        "lstm_rmse = math.sqrt(lstm_mse)\n",
        "\n",
        "lstm_cv_actual = lstm_std_act / lstm_actual.mean()\n",
        "lstm_cv_predicted = lstm_std_pred / lstm_predicted.mean()\n",
        "\n",
        "# Add LSTM results to the dataframe\n",
        "results.loc[0] = ['LSTM',\n",
        "                  lstm_mae,\n",
        "                  lstm_mse,\n",
        "                  lstm_rmse,\n",
        "                  lstm_cv_predicted,lstm_cv_actual]\n",
        "\n",
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-20A2k0lFu1F",
        "outputId": "d35299b5-13c0-4659-e240-ac306278d99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Algorithm        MAE          MSE       RMSE  CV Predicted  CV Actual\n",
            "0      LSTM  20.810256  1513.353298  38.901842      1.572647   1.030476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU-LSTM"
      ],
      "metadata": {
        "id": "p5YWmsWQh6s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, LSTM, Dense"
      ],
      "metadata": {
        "id": "e4W4maP8J2Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "dataset = df.copy()\n",
        "\n",
        "# Mengubah kolom Date menjadi tipe data datetime\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
        "\n",
        "# Mengurutkan dataset berdasarkan kolom Date\n",
        "dataset = dataset.sort_values('Date')\n",
        "\n",
        "# Memilih fitur yang akan digunakan untuk prediksi\n",
        "features = ['Temp Out', 'Humidity Out', 'Wind Speed', 'sum RainFall', 'Soil Moisture', 'FDRS Index']\n",
        "\n",
        "# Mengambil data yang akan digunakan\n",
        "data = dataset[features].values\n",
        "\n",
        "# Normalisasi data ke rentang 0-1\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Menentukan jumlah timestep dan fitur\n",
        "timesteps = 10  # Jumlah data sebelumnya yang akan digunakan untuk prediksi\n",
        "n_features = len(features)\n",
        "\n",
        "# Membuat dataset terpisah untuk pelatihan dan pengujian\n",
        "train_size = int(len(data_scaled) * 0.8)  # 80% data untuk pelatihan\n",
        "train_data = data_scaled[:train_size]\n",
        "test_data = data_scaled[train_size:]\n",
        "\n",
        "# Membagi data menjadi input dan output\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X.append(data[i:i + timesteps])\n",
        "        y.append(data[i + timesteps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "train_X, train_y = create_sequences(train_data, timesteps)\n",
        "test_X, test_y = create_sequences(test_data, timesteps)\n",
        "\n",
        "# Membangun model GRU-LSTM\n",
        "model = Sequential()\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(timesteps, n_features)))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Melatih model\n",
        "history_GRU_LSTM = model.fit(train_X, train_y, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Memprediksi data pengujian\n",
        "predicted = model.predict(test_X)\n",
        "\n",
        "# Mengembalikan data ke skala aslinya\n",
        "predicted = scaler.inverse_transform(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4L-BWJoh8an",
        "outputId": "8613ead0-cbde-48b8-84fc-09a01d9a8b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - 9s 16ms/step - loss: 0.0132\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0037\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0031\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0029\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0028\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0027\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0027\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0027\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0027\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0026\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0026\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0026\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0025\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0026\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0026\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0026\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0026\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0025\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0025\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0025\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0025\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0025\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0025\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0025\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0025\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0025\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0025\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0025\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0025\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0025\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0024\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0024\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0024\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0024\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0023\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0023\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0023\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0023\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0023\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0022\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0022\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0022\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0022\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0022\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0022\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0022\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0022\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0022\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0022\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0022\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0022\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0022\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0022\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0022\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0022\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0022\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0021\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0021\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0021\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0021\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0021\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0021\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0021\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0021\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0021\n",
            "49/49 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the actual test data and predicted values for LSTM\n",
        "GRU_lstm_actual = test_data[timesteps:]\n",
        "GRU_lstm_predicted = predicted\n",
        "\n",
        "GRU_lstm_std_act = np.std(GRU_lstm_actual)\n",
        "GRU_lstm_std_pred = np.std(GRU_lstm_predicted)\n",
        "\n",
        "# Calculate evaluation metrics for LSTM\n",
        "GRU_lstm_mae = mean_absolute_error(GRU_lstm_actual, GRU_lstm_predicted)\n",
        "GRU_lstm_mse = mean_squared_error(GRU_lstm_actual, GRU_lstm_predicted)\n",
        "GRU_lstm_rmse = math.sqrt(GRU_lstm_mse)\n",
        "\n",
        "GRU_lstm_cv_actual = GRU_lstm_std_act / GRU_lstm_actual.mean()\n",
        "GRU_lstm_cv_predicted = GRU_lstm_std_pred / GRU_lstm_predicted.mean()\n",
        "\n",
        "# Add LSTM results to the dataframe\n",
        "results.loc[1] = ['GRU-LSTM',\n",
        "                  GRU_lstm_mae,\n",
        "                  GRU_lstm_mse,\n",
        "                  GRU_lstm_rmse,\n",
        "                  GRU_lstm_cv_predicted,GRU_lstm_cv_actual]\n",
        "\n",
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQjtsRkowQmR",
        "outputId": "507a80ae-d607-434b-b082-15b9ff2a3965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Algorithm        MAE          MSE       RMSE  CV Predicted  CV Actual\n",
            "0      LSTM  20.810256  1513.353298  38.901842      1.572647   1.030476\n",
            "1  GRU-LSTM  20.762499  1500.318800  38.733949      1.567902   1.030476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN-LSTM"
      ],
      "metadata": {
        "id": "bPCKfGh0iC5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense"
      ],
      "metadata": {
        "id": "CT2F1ASSKqRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "dataset = df.copy()\n",
        "\n",
        "# Mengubah kolom Date menjadi tipe data datetime\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
        "\n",
        "# Mengurutkan dataset berdasarkan kolom Date\n",
        "dataset = dataset.sort_values('Date')\n",
        "\n",
        "# Memilih fitur yang akan digunakan untuk prediksi\n",
        "features = ['Temp Out', 'Humidity Out', 'Wind Speed', 'sum RainFall', 'Soil Moisture', 'FDRS Index']\n",
        "\n",
        "# Mengambil data yang akan digunakan\n",
        "data = dataset[features].values\n",
        "\n",
        "# Normalisasi data ke rentang 0-1\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Menentukan jumlah timestep dan fitur\n",
        "timesteps = 10  # Jumlah data sebelumnya yang akan digunakan untuk prediksi\n",
        "n_features = len(features)\n",
        "\n",
        "# Membuat dataset terpisah untuk pelatihan dan pengujian\n",
        "train_size = int(len(data_scaled) * 0.8)  # 80% data untuk pelatihan\n",
        "train_data = data_scaled[:train_size]\n",
        "test_data = data_scaled[train_size:]\n",
        "\n",
        "# Membagi data menjadi input dan output\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X.append(data[i:i + timesteps])\n",
        "        y.append(data[i + timesteps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "train_X, train_y = create_sequences(train_data, timesteps)\n",
        "test_X, test_y = create_sequences(test_data, timesteps)\n",
        "\n",
        "# Membangun model CNN-LSTM\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=(timesteps, n_features)))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Melatih model\n",
        "history_CNN_LSTM = model.fit(train_X, train_y, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Memprediksi data pengujian\n",
        "predicted = model.predict(test_X)\n",
        "\n",
        "# Mengembalikan data ke skala aslinya\n",
        "predicted = scaler.inverse_transform(predicted)\n",
        "\n",
        "# Menghitung rata-rata kesalahan absolut (Mean Absolute Error)\n",
        "#mae = np.mean(np.abs(test_data[timesteps:] - predicted))\n",
        "#print('Mean Absolute Error:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyyLYpbqiEtQ",
        "outputId": "dac4647f-b580-45fb-f288-d4436e3b4ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - 3s 5ms/step - loss: 0.0141\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0044\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0037\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0035\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0033\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0032\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0031\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0030\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0030\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0029\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0029\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0029\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0028\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0028\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0028\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0028\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0027\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0027\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0027\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0027\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0027\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0027\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0026\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0026\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0026\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0026\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0026\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0025\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0026\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.0025\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0025\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0025\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0025\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0025\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0025\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0025\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0025\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0025\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0025\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0025\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0025\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0024\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0024\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.0024\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0023\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0023\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0023\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0023\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0023\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0023\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0023\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0023\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0022\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.0023\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0023\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.0022\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0022\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0022\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0022\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "49/49 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the actual test data and predicted values for LSTM\n",
        "CNN_lstm_actual = test_data[timesteps:]\n",
        "CNN_lstm_predicted = predicted\n",
        "\n",
        "CNN_lstm_std_act = np.std(CNN_lstm_actual)\n",
        "CNN_lstm_std_pred = np.std(CNN_lstm_predicted)\n",
        "\n",
        "# Calculate evaluation metrics for LSTM\n",
        "CNN_lstm_mae = mean_absolute_error(CNN_lstm_actual, CNN_lstm_predicted)\n",
        "CNN_lstm_mse = mean_squared_error(CNN_lstm_actual, CNN_lstm_predicted)\n",
        "CNN_lstm_rmse = math.sqrt(CNN_lstm_mse)\n",
        "\n",
        "CNN_lstm_cv_actual = CNN_lstm_std_act / CNN_lstm_actual.mean()\n",
        "CNN_lstm_cv_predicted = CNN_lstm_std_pred / CNN_lstm_predicted.mean()\n",
        "\n",
        "# Add LSTM results to the dataframe\n",
        "results.loc[2] = ['CNN-LSTM',\n",
        "                  CNN_lstm_mae,\n",
        "                  CNN_lstm_mse,\n",
        "                  CNN_lstm_rmse,\n",
        "                  CNN_lstm_cv_predicted,CNN_lstm_cv_actual]\n",
        "\n",
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "KV2U6JjfKtnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2dc05bf-f7ee-42ea-e448-ea77b87dc3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Algorithm        MAE          MSE       RMSE  CV Predicted  CV Actual\n",
            "0      LSTM  20.810256  1513.353298  38.901842      1.572647   1.030476\n",
            "1  GRU-LSTM  20.762499  1500.318800  38.733949      1.567902   1.030476\n",
            "2  CNN-LSTM  20.878202  1515.864625  38.934106      1.565666   1.030476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BI-LSTM"
      ],
      "metadata": {
        "id": "BIuJhjJsmC30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM , Dense\n",
        "\n",
        "# Memuat dataset\n",
        "dataset = df.copy()\n",
        "\n",
        "# Mengubah kolom Date menjadi tipe data datetime\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
        "\n",
        "# Mengurutkan dataset berdasarkan kolom Date\n",
        "dataset = dataset.sort_values('Date')\n",
        "\n",
        "# Memilih fitur yang akan digunakan untuk prediksi\n",
        "features = ['Temp Out', 'Humidity Out', 'Wind Speed', 'sum RainFall', 'Soil Moisture', 'FDRS Index']\n",
        "\n",
        "# Mengambil data yang akan digunakan\n",
        "data = dataset[features].values\n",
        "\n",
        "# Normalisasi data ke rentang 0-1\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Menentukan jumlah timestep dan fitur\n",
        "timesteps = 10  # Jumlah data sebelumnya yang akan digunakan untuk prediksi\n",
        "n_features = len(features)\n",
        "\n",
        "# Membuat dataset terpisah untuk pelatihan dan pengujian\n",
        "train_size = int(len(data_scaled) * 0.8)  # 80% data untuk pelatihan\n",
        "train_data = data_scaled[:train_size]\n",
        "test_data = data_scaled[train_size:]\n",
        "\n",
        "# Membagi data menjadi input dan output\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X.append(data[i:i + timesteps])\n",
        "        y.append(data[i + timesteps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "train_X, train_y = create_sequences(train_data, timesteps)\n",
        "test_X, test_y = create_sequences(test_data, timesteps)\n",
        "\n",
        "# Membangun model Bi-LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(64), input_shape=(timesteps, n_features)))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Melatih model\n",
        "history_BI_LSTM = model.fit(train_X, train_y,validation_data=(test_X, test_y), epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Memprediksi data pengujian\n",
        "predicted = model.predict(test_X)\n",
        "\n",
        "# Mengembalikan data ke skala aslinya\n",
        "predicted = scaler.inverse_transform(predicted)\n",
        "\n",
        "# Menghitung rata-rata kesalahan absolut (Mean Absolute Error)\n",
        "#mae = np.mean(np.abs(test_data[timesteps:] - predicted))\n",
        "#print('Mean Absolute Error:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ump7s3MmmFbh",
        "outputId": "2f380964-704b-4206-8ad1-ebe730908777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - 9s 21ms/step - loss: 0.0154 - val_loss: 0.0039\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0046 - val_loss: 0.0028\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0039 - val_loss: 0.0025\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0034 - val_loss: 0.0023\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0032 - val_loss: 0.0020\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "49/49 [==============================] - 2s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the actual test data and predicted values for LSTM\n",
        "BI_lstm_actual = test_data[timesteps:]\n",
        "BI_lstm_predicted = predicted\n",
        "\n",
        "BI_lstm_std_act = np.std(BI_lstm_actual)\n",
        "BI_lstm_std_pred = np.std(BI_lstm_predicted)\n",
        "\n",
        "# Calculate evaluation metrics for LSTM\n",
        "BI_lstm_mae = mean_absolute_error(BI_lstm_actual, BI_lstm_predicted)\n",
        "BI_lstm_mse = mean_squared_error(BI_lstm_actual, BI_lstm_predicted)\n",
        "BI_lstm_rmse = math.sqrt(BI_lstm_mse)\n",
        "\n",
        "BI_lstm_cv_actual = BI_lstm_std_act / BI_lstm_actual.mean()\n",
        "BI_lstm_cv_predicted = BI_lstm_std_pred / BI_lstm_predicted.mean()\n",
        "\n",
        "# Add LSTM results to the dataframe\n",
        "results.loc[3] = ['BI-LSTM',\n",
        "                  BI_lstm_mae,\n",
        "                  BI_lstm_mse,\n",
        "                  BI_lstm_rmse,\n",
        "                  BI_lstm_cv_predicted,BI_lstm_cv_actual]\n",
        "\n",
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ1DYjVOLr53",
        "outputId": "0138108d-4cde-4f11-8429-c6c2e0e87d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Algorithm        MAE          MSE       RMSE  CV Predicted  CV Actual\n",
            "0      LSTM  20.810256  1513.353298  38.901842      1.572647   1.030476\n",
            "1  GRU-LSTM  20.762499  1500.318800  38.733949      1.567902   1.030476\n",
            "2  CNN-LSTM  20.878202  1515.864625  38.934106      1.565666   1.030476\n",
            "3   BI-LSTM  20.914586  1516.380095  38.940725      1.565353   1.030476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacked-LSTM"
      ],
      "metadata": {
        "id": "tllBqyqpmHsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Memuat dataset\n",
        "dataset = df.copy()\n",
        "\n",
        "# Mengubah kolom Date menjadi tipe data datetime\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
        "\n",
        "# Mengurutkan dataset berdasarkan kolom Date\n",
        "dataset = dataset.sort_values('Date')\n",
        "\n",
        "# Memilih fitur yang akan digunakan untuk prediksi\n",
        "features = ['Temp Out', 'Humidity Out', 'Wind Speed', 'sum RainFall', 'Soil Moisture', 'FDRS Index']\n",
        "\n",
        "# Mengambil data yang akan digunakan\n",
        "data = dataset[features].values\n",
        "\n",
        "# Normalisasi data ke rentang 0-1\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Menentukan jumlah timestep dan fitur\n",
        "timesteps = 10  # Jumlah data sebelumnya yang akan digunakan untuk prediksi\n",
        "n_features = len(features)\n",
        "\n",
        "# Membuat dataset terpisah untuk pelatihan dan pengujian\n",
        "train_size = int(len(data_scaled) * 0.8)  # 80% data untuk pelatihan\n",
        "train_data = data_scaled[:train_size]\n",
        "test_data = data_scaled[train_size:]\n",
        "\n",
        "# Membagi data menjadi input dan output\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X.append(data[i:i + timesteps])\n",
        "        y.append(data[i + timesteps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "train_X, train_y = create_sequences(train_data, timesteps)\n",
        "test_X, test_y = create_sequences(test_data, timesteps)\n",
        "\n",
        "# Membangun model Stacked LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(timesteps, n_features)))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Melatih model\n",
        "history_Stacked_LSTM = model.fit(train_X, train_y,validation_data=(test_X, test_y), epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Memprediksi data pengujian\n",
        "predicted = model.predict(test_X)\n",
        "\n",
        "# Mengembalikan data ke skala aslinya\n",
        "predicted = scaler.inverse_transform(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCqILVAYmKCT",
        "outputId": "894bfbdb-751a-4a11-c17d-04219fb848d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - 8s 22ms/step - loss: 0.0170 - val_loss: 0.0041\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0047 - val_loss: 0.0031\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0038 - val_loss: 0.0024\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0033 - val_loss: 0.0025\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0031 - val_loss: 0.0021\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0030 - val_loss: 0.0020\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0028 - val_loss: 0.0020\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0027 - val_loss: 0.0021\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0027 - val_loss: 0.0018\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "49/49 [==============================] - 1s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the actual test data and predicted values for LSTM\n",
        "STACKED_lstm_actual = test_data[timesteps:]\n",
        "STACKED_lstm_predicted = predicted\n",
        "\n",
        "STACKED_lstm_std_act = np.std(STACKED_lstm_actual)\n",
        "STACKED_lstm_std_pred = np.std(STACKED_lstm_predicted)\n",
        "\n",
        "# Calculate evaluation metrics for LSTM\n",
        "STACKED_lstm_mae = mean_absolute_error(STACKED_lstm_actual, STACKED_lstm_predicted)\n",
        "STACKED_lstm_mse = mean_squared_error(STACKED_lstm_actual, STACKED_lstm_predicted)\n",
        "STACKED_lstm_rmse = math.sqrt(STACKED_lstm_mse)\n",
        "\n",
        "STACKED_lstm_cv_actual = STACKED_lstm_std_act / STACKED_lstm_actual.mean()\n",
        "STACKED_lstm_cv_predicted = STACKED_lstm_std_pred / STACKED_lstm_predicted.mean()\n",
        "\n",
        "# Add LSTM results to the dataframe\n",
        "results.loc[4] = ['STACKED-LSTM',\n",
        "                  STACKED_lstm_mae,\n",
        "                  STACKED_lstm_mse,\n",
        "                  STACKED_lstm_rmse,\n",
        "                  STACKED_lstm_cv_predicted,STACKED_lstm_cv_actual]\n",
        "\n",
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVPmvevzxgI8",
        "outputId": "a638e026-0fc3-4436-d767-5e2ef3d86bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Algorithm        MAE          MSE       RMSE  CV Predicted  CV Actual\n",
            "0          LSTM  20.810256  1513.353298  38.901842      1.572647   1.030476\n",
            "1      GRU-LSTM  20.762499  1500.318800  38.733949      1.567902   1.030476\n",
            "2      CNN-LSTM  20.878202  1515.864625  38.934106      1.565666   1.030476\n",
            "3       BI-LSTM  20.914586  1516.380095  38.940725      1.565353   1.030476\n",
            "4  STACKED-LSTM  20.834718  1510.113259  38.860176      1.569203   1.030476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMPARISON"
      ],
      "metadata": {
        "id": "FLVPzkbtBjYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHvzu9-QxtbH",
        "outputId": "64fedbcf-2167-4fc7-bd70-97f72faf859a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Algorithm        MAE          MSE       RMSE  CV Predicted  CV Actual\n",
            "0          LSTM  20.810256  1513.353298  38.901842      1.572647   1.030476\n",
            "1      GRU-LSTM  20.762499  1500.318800  38.733949      1.567902   1.030476\n",
            "2      CNN-LSTM  20.878202  1515.864625  38.934106      1.565666   1.030476\n",
            "3       BI-LSTM  20.914586  1516.380095  38.940725      1.565353   1.030476\n",
            "4  STACKED-LSTM  20.834718  1510.113259  38.860176      1.569203   1.030476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan mencatat loss validation setiap epoch\n",
        "#history = model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Mendapatkan data loss dari history\n",
        "loss_LSTM = history_LSTM.history['loss']\n",
        "#loss_Attention_LSTM  = history_Attention_LSTM.history['loss']\n",
        "loss_GRU_LSTM  = history_GRU_LSTM.history['loss']\n",
        "loss_CNN_LSTM  = history_CNN_LSTM.history['loss']\n",
        "loss_BI_LSTM  = history_BI_LSTM.history['loss']\n",
        "loss_Stacked_LSTM  = history_Stacked_LSTM.history['loss']\n",
        "\n",
        "#val_loss = history_LSTM.history['val_loss']\n",
        "\n",
        "# Menampilkan grafik loss validation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, 100 + 1)\n",
        "\n",
        "plt.plot(epochs, loss_LSTM, 'r', label='LSTM')\n",
        "#plt.plot(epochs, loss_Attention_LSTM, 'g', label='LSTM-Attention')\n",
        "plt.plot(epochs, loss_GRU_LSTM, 'b', label='LSTM-GRU')\n",
        "plt.plot(epochs, loss_CNN_LSTM, 'c', label='LSTM-CNN')\n",
        "plt.plot(epochs, loss_BI_LSTM, 'm', label='LSTM-BI')\n",
        "plt.plot(epochs, loss_Stacked_LSTM, 'y', label='LSTM-Stacked')\n",
        "\n",
        "\n",
        "\n",
        "plt.title('Loss History')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "noUEuUWpBl6E",
        "outputId": "12a6766c-49d8-4763-bffc-0b8a219a31e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendapatkan nilai loss di awal epoch\n",
        "start_loss_LSTM = loss_LSTM[0]\n",
        "start_loss_GRU_LSTM = loss_GRU_LSTM[0]\n",
        "start_loss_CNN_LSTM = loss_CNN_LSTM[0]\n",
        "start_loss_BI_LSTM = loss_BI_LSTM[0]\n",
        "start_loss_Stacked_LSTM = loss_Stacked_LSTM[0]\n",
        "\n",
        "# Mendapatkan nilai loss di akhir epoch\n",
        "end_loss_LSTM = loss_LSTM[-1]\n",
        "end_loss_GRU_LSTM = loss_GRU_LSTM[-1]\n",
        "end_loss_CNN_LSTM = loss_CNN_LSTM[-1]\n",
        "end_loss_BI_LSTM = loss_BI_LSTM[-1]\n",
        "end_loss_Stacked_LSTM = loss_Stacked_LSTM[-1]\n",
        "\n",
        "# Membuat tabel\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Algoritma': ['LSTM', 'LSTM-GRU', 'LSTM-CNN', 'LSTM-BI', 'LSTM-Stacked'],\n",
        "    'Loss Awal Epoch': [start_loss_LSTM, start_loss_GRU_LSTM, start_loss_CNN_LSTM, start_loss_BI_LSTM, start_loss_Stacked_LSTM],\n",
        "    'Loss Akhir Epoch': [end_loss_LSTM, end_loss_GRU_LSTM, end_loss_CNN_LSTM, end_loss_BI_LSTM, end_loss_Stacked_LSTM]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tpfmxfAlA6t",
        "outputId": "bceae116-94f1-489a-dc2e-bbbf33b24624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Algoritma  Loss Awal Epoch  Loss Akhir Epoch\n",
            "0          LSTM         0.017440          0.002300\n",
            "1      LSTM-GRU         0.013208          0.002106\n",
            "2      LSTM-CNN         0.014085          0.002216\n",
            "3       LSTM-BI         0.015444          0.002259\n",
            "4  LSTM-Stacked         0.016982          0.002224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Algoritma': ['LSTM', 'LSTM-GRU', 'LSTM-CNN', 'LSTM-BI', 'LSTM-Stacked'],\n",
        "    'Loss Awal Epoch': [start_loss_LSTM, start_loss_GRU_LSTM, start_loss_CNN_LSTM, start_loss_BI_LSTM, start_loss_Stacked_LSTM]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df_sorted = df.sort_values(by='Loss Awal Epoch', ascending=False)\n",
        "\n",
        "print(df_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tOjXnV8n8go",
        "outputId": "667eea61-e4a2-4eb3-af32-599e4e40fd75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Algoritma  Loss Awal Epoch\n",
            "0          LSTM         0.017440\n",
            "4  LSTM-Stacked         0.016982\n",
            "3       LSTM-BI         0.015444\n",
            "2      LSTM-CNN         0.014085\n",
            "1      LSTM-GRU         0.013208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Algoritma': ['LSTM', 'LSTM-GRU', 'LSTM-CNN', 'LSTM-BI', 'LSTM-Stacked'],\n",
        "    'Loss Akhir Epoch': [end_loss_LSTM, end_loss_GRU_LSTM, end_loss_CNN_LSTM, end_loss_BI_LSTM, end_loss_Stacked_LSTM]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df_sorted = df.sort_values(by='Loss Akhir Epoch', ascending=False)\n",
        "\n",
        "print(df_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uBxDdLdoNON",
        "outputId": "bd519554-f3e5-4fe2-949f-e612bb1df0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Algoritma  Loss Akhir Epoch\n",
            "0          LSTM          0.002300\n",
            "3       LSTM-BI          0.002259\n",
            "4  LSTM-Stacked          0.002224\n",
            "2      LSTM-CNN          0.002216\n",
            "1      LSTM-GRU          0.002106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arsip"
      ],
      "metadata": {
        "id": "FqEXKXL0kw7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math\n",
        "\n",
        "# Repeat the above steps for Stacked-LSTM and other algorithms\n",
        "Stacked_lstm_actual = test_data[timesteps:]\n",
        "Stacked_lstm_predicted = predicted\n",
        "Stacked_lstm_mae = mean_absolute_error(Stacked_lstm_actual, Stacked_lstm_predicted)\n",
        "Stacked_lstm_mse = mean_squared_error(Stacked_lstm_actual, Stacked_lstm_predicted)\n",
        "Stacked_lstm_rmse = math.sqrt(Stacked_lstm_mse)\n",
        "Stacked_lstm_cv = Stacked_lstm_mae / Stacked_lstm_actual.mean()\n",
        "results.loc[5] = ['Stacked-LSTM',\n",
        "                  Stacked_lstm_mae,\n",
        "                  Stacked_lstm_mse,\n",
        "                  Stacked_lstm_rmse,\n",
        "                  Stacked_lstm_cv]\n",
        "\n",
        "# Display the results print(results) Change \"Stacked\" to \"Stacked\"\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "uyZByuzhL3s7",
        "outputId": "44bfc9b3-eda5-43f0-9835-4e680d36fc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0d7362404f72>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mStacked_lstm_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStacked_lstm_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mStacked_lstm_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStacked_lstm_mae\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mStacked_lstm_actual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m results.loc[5] = ['Stacked-LSTM',\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0mStacked_lstm_mae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   \u001b[0mStacked_lstm_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2158\u001b[0m                     \u001b[0;31m# must have conforming columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot set a row with mismatched columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mpGcGsWptO_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "results = pd.DataFrame(columns=['Algorithm', 'MAE', 'MSE', 'RMSE', 'CV Predicted', 'CV Actual'])\n",
        "\n",
        "# Repeat the below steps for each algorithm\n",
        "\n",
        "# Stacked-LSTM\n",
        "Stacked_lstm_actual = test_data[timesteps:]\n",
        "Stacked_lstm_predicted = predicted\n",
        "Stacked_lstm_mae = mean_absolute_error(Stacked_lstm_actual, Stacked_lstm_predicted)\n",
        "Stacked_lstm_mse = mean_squared_error(Stacked_lstm_actual, Stacked_lstm_predicted)\n",
        "Stacked_lstm_rmse = math.sqrt(Stacked_lstm_mse)\n",
        "Stacked_lstm_cv_predicted = Stacked_lstm_mae / Stacked_lstm_predicted.mean()\n",
        "Stacked_lstm_cv_actual = Stacked_lstm_mae / Stacked_lstm_actual.mean()\n",
        "\n",
        "results.loc[5] = ['Stacked-LSTM',\n",
        "                  Stacked_lstm_mae,\n",
        "                  Stacked_lstm_mse,\n",
        "                  Stacked_lstm_rmse,\n",
        "                  Stacked_lstm_cv_predicted,\n",
        "                  Stacked_lstm_cv_actual]\n",
        "\n",
        "# Repeat the above steps for other algorithms\n",
        "\n",
        "# Display the results\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "O1z4NZ_hsAjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z9Ajb2zoBk6Y"
      }
    }
  ]
}